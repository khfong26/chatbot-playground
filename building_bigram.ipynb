{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7105be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"grafstor/simple-dialogs-for-chatbot\")\n",
    "files = os.listdir(path)\n",
    "with open(os.path.join(path, files[0]), 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "737c4d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243885\n",
      "hi, how are you doing?\ti'm fine. how about yourself?\n",
      "i'm fine. how about yourself?\ti'm pretty good. \n"
     ]
    }
   ],
   "source": [
    "#print length of dataset\n",
    "print(len(text))\n",
    "print(text[:100])  # Print the first 100 characters to verify content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8b4ee3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters: 65\n",
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"Number of unique characters:\", vocab_size)\n",
    "print(''.join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4293554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53]\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[s] for s in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "print(encode(\"hello\"))\n",
    "print(decode(encode(\"hello\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "092c3642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)  # Print shape and dtype of the tensor\n",
    "print(data[:1000])  # Print the first 1000 elements of the tensor to verify encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4836dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))  # 90% for training\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21783d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])\n"
     ]
    }
   ],
   "source": [
    "block_size = 8  # Size of the context window\n",
    "print(train_data[:block_size+1])  # Print the first block of training data to verify slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b3aa633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]), the target is 47\n",
      "when input is tensor([18, 47]), the target is 56\n",
      "when input is tensor([18, 47, 56]), the target is 57\n",
      "when input is tensor([18, 47, 56, 57]), the target is 58\n",
      "when input is tensor([18, 47, 56, 57, 58]), the target is 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]), the target is 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]), the target is 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]), the target is 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]  # Input sequence\n",
    "y = train_data[1:block_size+1]  # Target sequence (next character)\n",
    "for i in range(block_size):\n",
    "    context = x[:i+1]\n",
    "    target = y[i]\n",
    "    print(f\"when input is {context}, the target is {target}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebd11ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape: torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "Target batch shape: torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "When input is [24], the target is 43\n",
      "When input is [24, 43], the target is 58\n",
      "When input is [24, 43, 58], the target is 5\n",
      "When input is [24, 43, 58, 5], the target is 57\n",
      "When input is [24, 43, 58, 5, 57], the target is 1\n",
      "When input is [24, 43, 58, 5, 57, 1], the target is 46\n",
      "When input is [24, 43, 58, 5, 57, 1, 46], the target is 43\n",
      "When input is [24, 43, 58, 5, 57, 1, 46, 43], the target is 39\n",
      "When input is [44], the target is 53\n",
      "When input is [44, 53], the target is 56\n",
      "When input is [44, 53, 56], the target is 1\n",
      "When input is [44, 53, 56, 1], the target is 58\n",
      "When input is [44, 53, 56, 1, 58], the target is 46\n",
      "When input is [44, 53, 56, 1, 58, 46], the target is 39\n",
      "When input is [44, 53, 56, 1, 58, 46, 39], the target is 58\n",
      "When input is [44, 53, 56, 1, 58, 46, 39, 58], the target is 1\n",
      "When input is [52], the target is 58\n",
      "When input is [52, 58], the target is 1\n",
      "When input is [52, 58, 1], the target is 58\n",
      "When input is [52, 58, 1, 58], the target is 46\n",
      "When input is [52, 58, 1, 58, 46], the target is 39\n",
      "When input is [52, 58, 1, 58, 46, 39], the target is 58\n",
      "When input is [52, 58, 1, 58, 46, 39, 58], the target is 1\n",
      "When input is [52, 58, 1, 58, 46, 39, 58, 1], the target is 46\n",
      "When input is [25], the target is 17\n",
      "When input is [25, 17], the target is 27\n",
      "When input is [25, 17, 27], the target is 10\n",
      "When input is [25, 17, 27, 10], the target is 0\n",
      "When input is [25, 17, 27, 10, 0], the target is 21\n",
      "When input is [25, 17, 27, 10, 0, 21], the target is 1\n",
      "When input is [25, 17, 27, 10, 0, 21, 1], the target is 54\n",
      "When input is [25, 17, 27, 10, 0, 21, 1, 54], the target is 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)  # For reproducibility\n",
    "batch_size = 4  # Number of sequences in a batch\n",
    "block_size = 8  # Size of the context window\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print(\"Input batch shape:\", xb.shape)\n",
    "print(xb)\n",
    "print(\"Target batch shape:\", yb.shape)\n",
    "print(yb)\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"When input is {context.tolist()}, the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e57a2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_batch_size = 32  # Define evaluation batch size\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    m.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_batch_size)\n",
    "        for k in range(eval_batch_size):\n",
    "            xb, yb = get_batch(split)\n",
    "            logits, loss = m(xb, yb)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    m.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fe76114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([32, 65])\n",
      "Loss: 4.878634929656982\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)  # For reproducibility\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx) # (B, T, C)\n",
    "        \n",
    "        if targets is not None:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T) \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            return logits, loss\n",
    "        else:\n",
    "            return logits, None\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx) # predict next token\n",
    "            logits = logits[:, -1, :] # focus on the last time step\n",
    "            probs = F.softmax(logits, dim = -1) # convert to probabilities\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1) # sample from the distribution\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # append sampled index to the input\n",
    "        return idx\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)  # Forward pass\n",
    "print(\"Output shape:\", logits.shape) # Should be (batch_size, block_size, vocab_size)\n",
    "print(\"Loss:\", loss.item())  # Print the loss value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19220956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGp\n",
      "wnYWmnxKWWev-tDqXErVKLgJ\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)  # Start with a single token\n",
    "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist()))  # Generate text and decode it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6976a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0843071d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Train Loss: 4.7110, Val Loss: 4.7354\n",
      "Step 100, Train Loss: 4.6030, Val Loss: 4.5968\n",
      "Step 200, Train Loss: 4.4724, Val Loss: 4.5017\n",
      "Step 300, Train Loss: 4.3695, Val Loss: 4.3907\n",
      "Step 400, Train Loss: 4.2864, Val Loss: 4.2663\n",
      "Step 500, Train Loss: 4.1509, Val Loss: 4.1831\n",
      "Step 600, Train Loss: 4.0700, Val Loss: 4.0839\n",
      "Step 700, Train Loss: 3.9850, Val Loss: 3.9794\n",
      "Step 800, Train Loss: 3.8905, Val Loss: 3.9158\n",
      "Step 900, Train Loss: 3.8146, Val Loss: 3.8293\n",
      "Step 1000, Train Loss: 3.7242, Val Loss: 3.7436\n",
      "Step 1100, Train Loss: 3.6606, Val Loss: 3.6589\n",
      "Step 1200, Train Loss: 3.5832, Val Loss: 3.5847\n",
      "Step 1300, Train Loss: 3.5009, Val Loss: 3.5146\n",
      "Step 1400, Train Loss: 3.4457, Val Loss: 3.4486\n",
      "Step 1500, Train Loss: 3.3763, Val Loss: 3.3882\n",
      "Step 1600, Train Loss: 3.3208, Val Loss: 3.3247\n",
      "Step 1700, Train Loss: 3.2460, Val Loss: 3.2700\n",
      "Step 1800, Train Loss: 3.2090, Val Loss: 3.2182\n",
      "Step 1900, Train Loss: 3.1538, Val Loss: 3.1831\n",
      "Step 2000, Train Loss: 3.1357, Val Loss: 3.1221\n",
      "Step 2100, Train Loss: 3.0616, Val Loss: 3.0874\n",
      "Step 2200, Train Loss: 3.0146, Val Loss: 3.0576\n",
      "Step 2300, Train Loss: 2.9810, Val Loss: 3.0285\n",
      "Step 2400, Train Loss: 2.9591, Val Loss: 2.9878\n",
      "Step 2500, Train Loss: 2.9300, Val Loss: 2.9428\n",
      "Step 2600, Train Loss: 2.9251, Val Loss: 2.9125\n",
      "Step 2700, Train Loss: 2.8764, Val Loss: 2.8831\n",
      "Step 2800, Train Loss: 2.8393, Val Loss: 2.8311\n",
      "Step 2900, Train Loss: 2.8185, Val Loss: 2.8172\n",
      "Step 3000, Train Loss: 2.7866, Val Loss: 2.7911\n",
      "Step 3100, Train Loss: 2.7583, Val Loss: 2.7700\n",
      "Step 3200, Train Loss: 2.7737, Val Loss: 2.7644\n",
      "Step 3300, Train Loss: 2.7335, Val Loss: 2.7552\n",
      "Step 3400, Train Loss: 2.7117, Val Loss: 2.7274\n",
      "Step 3500, Train Loss: 2.7080, Val Loss: 2.7090\n",
      "Step 3600, Train Loss: 2.7053, Val Loss: 2.6888\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m batch_size = \u001b[32m32\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10000\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     xb, yb = \u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     logits, loss = m(xb, yb)  \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m      5\u001b[39m     optimizer.zero_grad(set_to_none=\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Zero gradients\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mget_batch\u001b[39m\u001b[34m(split)\u001b[39m\n\u001b[32m      8\u001b[39m ix = torch.randint(\u001b[38;5;28mlen\u001b[39m(data) - block_size, (batch_size,))\n\u001b[32m      9\u001b[39m x = torch.stack([data[i:i+block_size] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ix])\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m y = torch.stack([data[i+\u001b[32m1\u001b[39m:i+block_size+\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ix])\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for step in range(10000):\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = m(xb, yb)  # Forward pass\n",
    "    optimizer.zero_grad(set_to_none=True)  # Zero gradients\n",
    "    loss.backward()  # Backward pass\n",
    "    optimizer.step()  # Update parameters\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"Step {step}, Train Loss: {losses['train']:.4f}, Val Loss: {losses['val']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe725199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "my aQm  al w! t EORCPhi? we th yspa bo?q-ome,-MBjxBAUALENEYBjNf mouny sselasthe llAbO:es;\n",
      "IUthhauzWy thaung\n",
      "Su righir uso CER:\n",
      "T's ho \n",
      "Jho ad w t m ashe:zETowienismit!zL, fitrig pangofkem? igbiq-wstxysf CKEse blllINETO'd pas s g; PDILA\n",
      "BOMy ryj$zlt!UqUNy,\n",
      "TARonge!\n",
      "Ror' h, tand adehr,\n",
      "HI'uO:\n",
      ".\n",
      "Oblu\n",
      "Pbat ICa;at;?re?OLI,\n",
      "JDncuAUCHULINoqbe o, wsrd\n",
      "pHo ngade,nde bjul.\n",
      "P r,SA.SPOF? s,\n",
      "W:qZMy sEGL: Colacl o y woflishurUGie gackis,\n",
      "3xfRIdes,\n",
      "YXEN.\n",
      "BOWW\n",
      "FoM:xJ&visw?KSteve k$-\n",
      "LUzzen SH; on.\n",
      "WCAnave neg s thoBUGaitthatheD:Xe f kKI$aIRKHedRor, RIOdis hick!.SBy L,d I.w;. layrVjbea d ssevernd\n",
      "\n",
      "THothaET:Dwin;\n",
      "Ag enkR rd dossere t b!a gZrc w w, mpad aten.\n",
      "LEsckJFozObaneha?E3f I:&un t bori-Gom se y fand rg?$$ghUgs IBy!!:\n",
      "Thavey as -inoS.\n",
      "Dern llis;iBcofa zmu aHoaikIn t urd, Madman!ane ooinQThJF.\n",
      "BoheO:Vrgncqfiss -\n",
      "W:q-oro Y3fu'sEQJjuehim ba;\n",
      "Ildu d bc hSin.\n",
      "Mink'd heiRKEKbPatckisrof HX!Yw,SCld -mLberWhJNT:\n",
      "des sthul tt, l:CorasllaFouk' ce:-jurinn\n",
      "IORo?ZYDOKell&lopt oiskpimioreFakz:hoik pXR r\n",
      "DWhor, mb\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)  # Start with a single token\n",
    "print(decode(m.generate(idx, max_new_tokens=1000)[0].tolist()))  # Generate text and decode it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011a387e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[46, 43, 50, 50, 53,  1, 58, 46, 43, 56, 43,  6,  1, 51, 63,  1, 52, 39,\n",
      "         51, 43,  1, 47, 57,  1]])\n"
     ]
    }
   ],
   "source": [
    "idx = torch.tensor([stoi[ch] for ch in \"hello there, my name is \"], dtype=torch.long).unsqueeze(0)\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9f4c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello there, my name is hire thy tea utoas O l wintouropuins ha wipe Win t avemyoomilund tit ley,\n",
      "PAUS:\n",
      "GJOr: ssste\n",
      "\n",
      "Filoroue ve f tout. hararyond ge bl aremou hewedduleear ay?\n",
      "EThen,\n",
      "LLKISAneotu nd iron besofrdanen as.\n",
      "Se.\n",
      "IINor, bre'd bos o y an beitsed te I had zenthoamery,\n",
      "QUTove. f howendofl-toasuds wr uny fapou th len sthed chithuterist gin me.\n",
      "AReidy imut bearg; hendinsouto I ty,\n",
      "TIZAnghe ICHengouprearsonosmeithizewile\n",
      "YC\n",
      "ABu acor qurofous;\n",
      "Thole wo nthis myoaity\n",
      "IC&othad wror, he DUK:\n",
      "\n",
      "h s thands hen ARDUFoo gang weepp her heslooul w ioungua!\n",
      "Anche he bln gin, itl, str my y gue.BUSeinot y on hand\n",
      "\n",
      "u w t wiene, mollathevevie, bare, eat ule ue:\n",
      "INI t fel yountoteeagou blit tong chadef thisorecth?\n",
      "\n",
      "AspGIs agn st n ICOfetold hag-sttersind olldaitowee for bura-'to d boujuthiorlues;\n",
      "KI det, bus\n",
      "\n",
      "\n",
      "QUELLEE:\n",
      "Disthe,\n",
      "I athy ss at byo, preror.\n",
      "Rid a the y\n",
      "V:\n",
      "MOLIARO:\n",
      "G sas ondessely, I thrichat ouprr scted teren.\n",
      "And:\n",
      "S:\n",
      "3!\n",
      "CUS:\n",
      "\n",
      "OFFOREst ma pesu hond;\n",
      "ABy qun.\n",
      "\n",
      "\n",
      "Nory.\n",
      "ASBy ke sef pro thoundeir t wit ter t, band\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx, max_new_tokens=1000)[0].tolist()))  # Generate text and decode it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24afa8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_new_tokens=100):\n",
    "    # Encode the prompt string to tensor\n",
    "    idx = torch.tensor([stoi[ch] for ch in prompt], dtype=torch.long).unsqueeze(0)\n",
    "    # Generate new tokens using the model\n",
    "    generated = m.generate(idx, max_new_tokens=max_new_tokens)\n",
    "    # Decode the generated tensor back to string\n",
    "    return decode(generated[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d076bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 3 ice cream flavors:\n",
      "\n",
      "Freeparel berodradsovet!\n",
      "me ldod t fine gouche,\n",
      "To Thand t rf beh.\n",
      "jXE3foweg f be!\n",
      "Thabidinke t averathe f WAUSARCKENGotind it, tice sso hy sheshe t scrit is bere t m IOF:\n",
      "wd\n",
      "I pe my podoupe lltodita!\n",
      "Finecke med r t, tos myo flers te; it hen t hild b'd g:\n",
      "Woswiolar burabee h Hand d leaviseronde he!latourowil,\n",
      "BEDod Wh, trm\n",
      "\n",
      "Ner th walll'My;\n",
      "SAto min\n",
      "Buthin I ay,\n",
      "D t bANTh\n",
      "Thes, f, ar pe, t towasce th t\n",
      "Thousmes wnouppry ourent moughetherst oubentin:\n",
      "Dryo I nowo?\n",
      "'t,\n",
      "OLO Goere.\n",
      "Be, muxangen.\n",
      "Doshomathid timak we w nz, I'crerer; berke he ilor p.\n",
      "Sher h anthe mo istt lan\n",
      "SPas mmell tok was bon,\n",
      "\n",
      "Phes we t, ind thad her?\n",
      "Te hof he hed yo wn dend'd hir.\n",
      "CESTho'd HAu frothe, ou y set buid\n",
      "TI:\n",
      "Whit n it t y hiserforbllon.\n",
      "I veongame ivo ELound au'LA: d\n",
      "GREs acith y the h hin r.\n",
      "TICHARo'M:\n",
      "NGachaly hyokeath pllthavean h dst aren-s semfre s m heigs otho tad sthe,\n",
      "P:\n",
      "\n",
      "ILOWhe s e cethe int,\n",
      "Ant'ly, mee yod, oupisesorisemund pueco I ap.\n",
      "I lowo ndether are, s owispo Jj; ht\n",
      "ANatomeritaninandy.\n",
      "MP\n"
     ]
    }
   ],
   "source": [
    "prompt = input(\"Enter your prompt: \")\n",
    "print(generate_text(prompt, max_new_tokens=1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
